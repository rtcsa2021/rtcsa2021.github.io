{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FastSLAM 2.0 example\n",
    "The blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.\n",
    "The red points are particles of FastSLAM.\n",
    "Black points are landmarks, blue crosses are estimated landmark positions by FastSLAM.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fast SLAM covariance\n",
    "Q = np.diag([3.0, np.deg2rad(10.0)]) ** 2\n",
    "R = np.diag([1.0, np.deg2rad(20.0)]) ** 2\n",
    "\n",
    "#  Simulation parameter\n",
    "Q_sim = np.diag([0.3, np.deg2rad(2.0)]) ** 2\n",
    "R_sim = np.diag([0.5, np.deg2rad(10.0)]) ** 2\n",
    "OFFSET_YAW_RATE_NOISE = 0.01\n",
    "\n",
    "DT = 0.1  # time tick [s]\n",
    "SIM_TIME = 50.0  # simulation time [s]\n",
    "MAX_RANGE = 20.0  # maximum observation range\n",
    "M_DIST_TH = 2.0  # Threshold of Mahalanobis distance for data association.\n",
    "STATE_SIZE = 3  # State size [x,y,yaw]\n",
    "LM_SIZE = 2  # LM state size [x,y]\n",
    "N_PARTICLE = 100  # number of particle\n",
    "NTH = N_PARTICLE / 1.5  # Number of particle for re-sampling\n",
    "\n",
    "show_animation = True\n",
    "\n",
    "\n",
    "class Particle:\n",
    "\n",
    "    def __init__(self, N_LM):\n",
    "        self.w = 1.0 / N_PARTICLE\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.yaw = 0.0\n",
    "        self.P = np.eye(3)\n",
    "        # landmark x-y positions\n",
    "        self.lm = np.zeros((N_LM, LM_SIZE))\n",
    "        # landmark position covariance\n",
    "        self.lmP = np.zeros((N_LM * LM_SIZE, LM_SIZE))\n",
    "\n",
    "\n",
    "def fast_slam2(particles, u, z):\n",
    "    particles = predict_particles(particles, u)\n",
    "\n",
    "    particles = update_with_observation(particles, z)\n",
    "\n",
    "    particles = resampling(particles)\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def normalize_weight(particles):\n",
    "    sum_w = sum([p.w for p in particles])\n",
    "\n",
    "    try:\n",
    "        for i in range(N_PARTICLE):\n",
    "            particles[i].w /= sum_w\n",
    "    except ZeroDivisionError:\n",
    "        for i in range(N_PARTICLE):\n",
    "            particles[i].w = 1.0 / N_PARTICLE\n",
    "\n",
    "        return particles\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def calc_final_state(particles):\n",
    "    xEst = np.zeros((STATE_SIZE, 1))\n",
    "\n",
    "    particles = normalize_weight(particles)\n",
    "\n",
    "    for i in range(N_PARTICLE):\n",
    "        xEst[0, 0] += particles[i].w * particles[i].x\n",
    "        xEst[1, 0] += particles[i].w * particles[i].y\n",
    "        xEst[2, 0] += particles[i].w * particles[i].yaw\n",
    "\n",
    "    xEst[2, 0] = pi_2_pi(xEst[2, 0])\n",
    "\n",
    "    return xEst\n",
    "\n",
    "\n",
    "def predict_particles(particles, u):\n",
    "    for i in range(N_PARTICLE):\n",
    "        px = np.zeros((STATE_SIZE, 1))\n",
    "        px[0, 0] = particles[i].x\n",
    "        px[1, 0] = particles[i].y\n",
    "        px[2, 0] = particles[i].yaw\n",
    "        ud = u + (np.random.randn(1, 2) @ R ** 0.5).T  # add noise\n",
    "        px = motion_model(px, ud)\n",
    "        particles[i].x = px[0, 0]\n",
    "        particles[i].y = px[1, 0]\n",
    "        particles[i].yaw = px[2, 0]\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def add_new_lm(particle, z, Q_cov):\n",
    "    r = z[0]\n",
    "    b = z[1]\n",
    "    lm_id = int(z[2])\n",
    "\n",
    "    s = math.sin(pi_2_pi(particle.yaw + b))\n",
    "    c = math.cos(pi_2_pi(particle.yaw + b))\n",
    "\n",
    "    particle.lm[lm_id, 0] = particle.x + r * c\n",
    "    particle.lm[lm_id, 1] = particle.y + r * s\n",
    "\n",
    "    # covariance\n",
    "    dx = r * c\n",
    "    dy = r * s\n",
    "    d2 = dx ** 2 + dy ** 2\n",
    "    d = math.sqrt(d2)\n",
    "    Gz = np.array([[dx / d, dy / d],\n",
    "                   [-dy / d2, dx / d2]])\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2] = np.linalg.inv(\n",
    "        Gz) @ Q_cov @ np.linalg.inv(Gz.T)\n",
    "\n",
    "    return particle\n",
    "\n",
    "\n",
    "def compute_jacobians(particle, xf, Pf, Q_cov):\n",
    "    dx = xf[0, 0] - particle.x\n",
    "    dy = xf[1, 0] - particle.y\n",
    "    d2 = dx ** 2 + dy ** 2\n",
    "    d = math.sqrt(d2)\n",
    "\n",
    "    zp = np.array(\n",
    "        [d, pi_2_pi(math.atan2(dy, dx) - particle.yaw)]).reshape(2, 1)\n",
    "\n",
    "    Hv = np.array([[-dx / d, -dy / d, 0.0],\n",
    "                   [dy / d2, -dx / d2, -1.0]])\n",
    "\n",
    "    Hf = np.array([[dx / d, dy / d],\n",
    "                   [-dy / d2, dx / d2]])\n",
    "\n",
    "    Sf = Hf @ Pf @ Hf.T + Q_cov\n",
    "\n",
    "    return zp, Hv, Hf, Sf\n",
    "\n",
    "\n",
    "def update_kf_with_cholesky(xf, Pf, v, Q_cov, Hf):\n",
    "    PHt = Pf @ Hf.T\n",
    "    S = Hf @ PHt + Q_cov\n",
    "\n",
    "    S = (S + S.T) * 0.5\n",
    "    SChol = np.linalg.cholesky(S).T\n",
    "    SCholInv = np.linalg.inv(SChol)\n",
    "    W1 = PHt @ SCholInv\n",
    "    W = W1 @ SCholInv.T\n",
    "\n",
    "    x = xf + W @ v\n",
    "    P = Pf - W1 @ W1.T\n",
    "\n",
    "    return x, P\n",
    "\n",
    "\n",
    "def update_landmark(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2])\n",
    "\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q_cov)\n",
    "\n",
    "    dz = z[0:2].reshape(2, 1) - zp\n",
    "    dz[1, 0] = pi_2_pi(dz[1, 0])\n",
    "\n",
    "    xf, Pf = update_kf_with_cholesky(xf, Pf, dz, Q, Hf)\n",
    "\n",
    "    particle.lm[lm_id, :] = xf.T\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2, :] = Pf\n",
    "\n",
    "    return particle\n",
    "\n",
    "\n",
    "def compute_weight(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2])\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q_cov)\n",
    "\n",
    "    dz = z[0:2].reshape(2, 1) - zp\n",
    "    dz[1, 0] = pi_2_pi(dz[1, 0])\n",
    "\n",
    "    try:\n",
    "        invS = np.linalg.inv(Sf)\n",
    "    except np.linalg.linalg.LinAlgError:\n",
    "        return 1.0\n",
    "\n",
    "    num = math.exp(-0.5 * dz.T @ invS @ dz)\n",
    "    den = 2.0 * math.pi * math.sqrt(np.linalg.det(Sf))\n",
    "\n",
    "    w = num / den\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def proposal_sampling(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = particle.lm[lm_id, :].reshape(2, 1)\n",
    "    Pf = particle.lmP[2 * lm_id:2 * lm_id + 2]\n",
    "    # State\n",
    "    x = np.array([particle.x, particle.y, particle.yaw]).reshape(3, 1)\n",
    "    P = particle.P\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q_cov)\n",
    "\n",
    "    Sfi = np.linalg.inv(Sf)\n",
    "    dz = z[0:2].reshape(2, 1) - zp\n",
    "    dz[1] = pi_2_pi(dz[1])\n",
    "\n",
    "    Pi = np.linalg.inv(P)\n",
    "\n",
    "    particle.P = np.linalg.inv(Hv.T @ Sfi @ Hv + Pi)  # proposal covariance\n",
    "    x += particle.P @ Hv.T @ Sfi @ dz  # proposal mean\n",
    "\n",
    "    particle.x = x[0, 0]\n",
    "    particle.y = x[1, 0]\n",
    "    particle.yaw = x[2, 0]\n",
    "\n",
    "    return particle\n",
    "\n",
    "\n",
    "def update_with_observation(particles, z):\n",
    "    for iz in range(len(z[0, :])):\n",
    "        landmark_id = int(z[2, iz])\n",
    "\n",
    "        for ip in range(N_PARTICLE):\n",
    "            # new landmark\n",
    "            if abs(particles[ip].lm[landmark_id, 0]) <= 0.01:\n",
    "                particles[ip] = add_new_lm(particles[ip], z[:, iz], Q)\n",
    "            # known landmark\n",
    "            else:\n",
    "                w = compute_weight(particles[ip], z[:, iz], Q)\n",
    "                particles[ip].w *= w\n",
    "\n",
    "                particles[ip] = update_landmark(particles[ip], z[:, iz], Q)\n",
    "                particles[ip] = proposal_sampling(particles[ip], z[:, iz], Q)\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def resampling(particles):\n",
    "    \"\"\"\n",
    "    low variance re-sampling\n",
    "    \"\"\"\n",
    "\n",
    "    particles = normalize_weight(particles)\n",
    "\n",
    "    pw = []\n",
    "    for i in range(N_PARTICLE):\n",
    "        pw.append(particles[i].w)\n",
    "\n",
    "    pw = np.array(pw)\n",
    "\n",
    "    n_eff = 1.0 / (pw @ pw.T)  # Effective particle number\n",
    "\n",
    "    if n_eff < NTH:  # resampling\n",
    "        w_cum = np.cumsum(pw)\n",
    "        base = np.cumsum(pw * 0.0 + 1 / N_PARTICLE) - 1 / N_PARTICLE\n",
    "        resample_id = base + np.random.rand(base.shape[0]) / N_PARTICLE\n",
    "\n",
    "        inds = []\n",
    "        ind = 0\n",
    "        for ip in range(N_PARTICLE):\n",
    "            while (ind < w_cum.shape[0] - 1) \\\n",
    "                    and (resample_id[ip] > w_cum[ind]):\n",
    "                ind += 1\n",
    "            inds.append(ind)\n",
    "\n",
    "        tmp_particles = particles[:]\n",
    "        for i in range(len(inds)):\n",
    "            particles[i].x = tmp_particles[inds[i]].x\n",
    "            particles[i].y = tmp_particles[inds[i]].y\n",
    "            particles[i].yaw = tmp_particles[inds[i]].yaw\n",
    "            particles[i].lm = tmp_particles[inds[i]].lm[:, :]\n",
    "            particles[i].lmP = tmp_particles[inds[i]].lmP[:, :]\n",
    "            particles[i].w = 1.0 / N_PARTICLE\n",
    "\n",
    "    return particles\n",
    "\n",
    "\n",
    "def calc_input(time):\n",
    "    if time <= 3.0:  # wait at first\n",
    "        v = 0.0\n",
    "        yaw_rate = 0.0\n",
    "    else:\n",
    "        v = 1.0  # [m/s]\n",
    "        yaw_rate = 0.1  # [rad/s]\n",
    "\n",
    "    u = np.array([v, yaw_rate]).reshape(2, 1)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def observation(xTrue, xd, u, RFID):\n",
    "    # calc true state\n",
    "    xTrue = motion_model(xTrue, u)\n",
    "\n",
    "    # add noise to range observation\n",
    "    z = np.zeros((3, 0))\n",
    "\n",
    "    for i in range(len(RFID[:, 0])):\n",
    "\n",
    "        dx = RFID[i, 0] - xTrue[0, 0]\n",
    "        dy = RFID[i, 1] - xTrue[1, 0]\n",
    "        d = math.hypot(dx, dy)\n",
    "        angle = pi_2_pi(math.atan2(dy, dx) - xTrue[2, 0])\n",
    "        if d <= MAX_RANGE:\n",
    "            dn = d + np.random.randn() * Q_sim[0, 0] ** 0.5  # add noise\n",
    "            angle_noise = np.random.randn() * Q_sim[1, 1] ** 0.5\n",
    "            angle_with_noise = angle + angle_noise  # add noise\n",
    "            zi = np.array([dn, pi_2_pi(angle_with_noise), i]).reshape(3, 1)\n",
    "            z = np.hstack((z, zi))\n",
    "\n",
    "    # add noise to input\n",
    "    ud1 = u[0, 0] + np.random.randn() * R_sim[0, 0] ** 0.5\n",
    "    ud2 = u[1, 0] + np.random.randn() * R_sim[\n",
    "        1, 1] ** 0.5 + OFFSET_YAW_RATE_NOISE\n",
    "    ud = np.array([ud1, ud2]).reshape(2, 1)\n",
    "\n",
    "    xd = motion_model(xd, ud)\n",
    "\n",
    "    return xTrue, z, xd, ud\n",
    "\n",
    "\n",
    "def motion_model(x, u):\n",
    "    F = np.array([[1.0, 0, 0],\n",
    "                  [0, 1.0, 0],\n",
    "                  [0, 0, 1.0]])\n",
    "\n",
    "    B = np.array([[DT * math.cos(x[2, 0]), 0],\n",
    "                  [DT * math.sin(x[2, 0]), 0],\n",
    "                  [0.0, DT]])\n",
    "\n",
    "    x = F @ x + B @ u\n",
    "\n",
    "    x[2, 0] = pi_2_pi(x[2, 0])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def pi_2_pi(angle):\n",
    "    return (angle + math.pi) % (2 * math.pi) - math.pi\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(__file__ + \" start!!\")\n",
    "\n",
    "    time = 0.0\n",
    "\n",
    "    # RFID positions [x, y]\n",
    "    RFID = np.array([[10.0, -2.0],\n",
    "                     [15.0, 10.0],\n",
    "                     [15.0, 15.0],\n",
    "                     [10.0, 20.0],\n",
    "                     [3.0, 15.0],\n",
    "                     [-5.0, 20.0],\n",
    "                     [-5.0, 5.0],\n",
    "                     [-10.0, 15.0]\n",
    "                     ])\n",
    "    n_landmark = RFID.shape[0]\n",
    "\n",
    "    # State Vector [x y yaw v]'\n",
    "    xEst = np.zeros((STATE_SIZE, 1))  # SLAM estimation\n",
    "    xTrue = np.zeros((STATE_SIZE, 1))  # True state\n",
    "    xDR = np.zeros((STATE_SIZE, 1))  # Dead reckoning\n",
    "\n",
    "    # history\n",
    "    hxEst = xEst\n",
    "    hxTrue = xTrue\n",
    "    hxDR = xTrue\n",
    "\n",
    "    particles = [Particle(n_landmark) for _ in range(N_PARTICLE)]\n",
    "\n",
    "    while SIM_TIME >= time:\n",
    "        time += DT\n",
    "        u = calc_input(time)\n",
    "\n",
    "        xTrue, z, xDR, ud = observation(xTrue, xDR, u, RFID)\n",
    "\n",
    "        particles = fast_slam2(particles, ud, z)\n",
    "\n",
    "        xEst = calc_final_state(particles)\n",
    "\n",
    "        x_state = xEst[0: STATE_SIZE]\n",
    "\n",
    "        # store data history\n",
    "        hxEst = np.hstack((hxEst, x_state))\n",
    "        hxDR = np.hstack((hxDR, xDR))\n",
    "        hxTrue = np.hstack((hxTrue, xTrue))\n",
    "\n",
    "        if show_animation:  # pragma: no cover\n",
    "            plt.cla()\n",
    "            # for stopping simulation with the esc key.\n",
    "            plt.gcf().canvas.mpl_connect(\n",
    "                'key_release_event',\n",
    "                lambda event: [exit(0) if event.key == 'escape' else None])\n",
    "            plt.plot(RFID[:, 0], RFID[:, 1], \"*k\")\n",
    "\n",
    "            for iz in range(len(z[:, 0])):\n",
    "                landmark_id = int(z[2, iz])\n",
    "                plt.plot([xEst[0], RFID[landmark_id, 0]], [\n",
    "                    xEst[1], RFID[landmark_id, 1]], \"-k\")\n",
    "\n",
    "            for i in range(N_PARTICLE):\n",
    "                plt.plot(particles[i].x, particles[i].y, \".r\")\n",
    "                plt.plot(particles[i].lm[:, 0], particles[i].lm[:, 1], \"xb\")\n",
    "\n",
    "            plt.plot(hxTrue[0, :], hxTrue[1, :], \"-b\")\n",
    "            plt.plot(hxDR[0, :], hxDR[1, :], \"-k\")\n",
    "            plt.plot(hxEst[0, :], hxEst[1, :], \"-r\")\n",
    "            plt.plot(xEst[0], xEst[1], \"xk\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.grid(True)\n",
    "            plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-fb1aa36de767>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" start!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
